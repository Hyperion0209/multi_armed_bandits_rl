# multi_armed_bandits_rl
A comprehensive implementation and analysis of multi-armed bandit algorithms - Upper Confidence Bound (UCB), Kullback-Leibler UCB (KL-UCB) and Thompson Sampling
